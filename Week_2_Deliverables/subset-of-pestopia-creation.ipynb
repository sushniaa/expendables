{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5192802,"sourceType":"datasetVersion","datasetId":3019285}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install roboflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:40:27.446434Z","iopub.execute_input":"2025-06-11T10:40:27.446648Z","iopub.status.idle":"2025-06-11T10:40:36.517261Z","shell.execute_reply.started":"2025-06-11T10:40:27.446628Z","shell.execute_reply":"2025-06-11T10:40:36.516306Z"}},"outputs":[{"name":"stdout","text":"Collecting roboflow\n  Downloading roboflow-1.1.66-py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\nCollecting idna==3.7 (from roboflow)\n  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7.2)\nRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.26.4)\nCollecting opencv-python-headless==4.10.0.84 (from roboflow)\n  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\nCollecting pillow-heif>=0.18.0 (from roboflow)\n  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\nCollecting python-dotenv (from roboflow)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\nRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\nRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\nRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\nRequirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\nCollecting filetype (from roboflow)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.57.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->roboflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->roboflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.5->roboflow) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.5->roboflow) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.5->roboflow) (2024.2.0)\nDownloading roboflow-1.1.66-py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: filetype, python-dotenv, pillow-heif, idna, opencv-python-headless, roboflow\n  Attempting uninstall: idna\n    Found existing installation: idna 3.10\n    Uninstalling idna-3.10:\n      Successfully uninstalled idna-3.10\n  Attempting uninstall: opencv-python-headless\n    Found existing installation: opencv-python-headless 4.11.0.86\n    Uninstalling opencv-python-headless-4.11.0.86:\n      Successfully uninstalled opencv-python-headless-4.11.0.86\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.66\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport os\nimport pandas as pd\nimport shutil\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom roboflow import Roboflow\nimport roboflow.core.workspace  # For workspace-related methods\nimport requests","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:40:36.519549Z","iopub.execute_input":"2025-06-11T10:40:36.519754Z","iopub.status.idle":"2025-06-11T10:40:45.140377Z","shell.execute_reply.started":"2025-06-11T10:40:36.519734Z","shell.execute_reply":"2025-06-11T10:40:45.139615Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Step 1: Define paths\nbase_dir = \"/kaggle/input/pestopia/Datasets/Pest_Dataset\"\npesticide_csv = \"/kaggle/input/pestopia/Datasets/Pesticide_Dataset/Pesticides.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:40:45.141162Z","iopub.execute_input":"2025-06-11T10:40:45.141544Z","iopub.status.idle":"2025-06-11T10:40:45.145575Z","shell.execute_reply.started":"2025-06-11T10:40:45.141525Z","shell.execute_reply":"2025-06-11T10:40:45.144908Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Step 2: Analyze the dataset structure and check for missing files\ndef analyze_dataset(base_dir):\n    pest_classes = os.listdir(base_dir)  # List of pest class directories (e.g., Adristyrannus)\n    pest_classes = [p for p in pest_classes if os.path.isdir(os.path.join(base_dir, p))]\n    print(f\"Total number of pest classes: {len(pest_classes)}\")\n\n    # Dictionary to store image paths and labels\n    image_paths = []\n    labels = []\n    label_to_idx = {pest: idx for idx, pest in enumerate(pest_classes)}\n    missing_files = 0\n    corrupted_files = 0\n\n    for pest in tqdm(pest_classes, desc=\"Analyzing dataset\"):\n        pest_dir = os.path.join(base_dir, pest)\n        if not os.path.isdir(pest_dir):\n            print(f\"Directory missing: {pest_dir}\")\n            continue\n\n        for img_name in os.listdir(pest_dir):\n            img_path = os.path.join(pest_dir, img_name)\n            try:\n                # Try to open the image to check if it's valid\n                with Image.open(img_path) as img:\n                    img.verify()  # Verify image integrity\n                    img = Image.open(img_path).convert('RGB')  # Reopen to ensure it can be loaded\n                image_paths.append(img_path)\n                labels.append(label_to_idx[pest])\n            except Exception as e:\n                print(f\"Corrupted image: {img_path}, Error: {e}\")\n                corrupted_files += 1\n                missing_files += 1\n\n    print(f\"Total images found: {len(image_paths)}\")\n    print(f\"Missing or corrupted files: {missing_files}\")\n    print(f\"Corrupted files: {corrupted_files}\")\n    return image_paths, labels, label_to_idx\n\n# Run the analysis\nimage_paths, labels, label_to_idx = analyze_dataset(base_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:40:45.146370Z","iopub.execute_input":"2025-06-11T10:40:45.146598Z","iopub.status.idle":"2025-06-11T10:46:31.919775Z","shell.execute_reply.started":"2025-06-11T10:40:45.146584Z","shell.execute_reply":"2025-06-11T10:46:31.918850Z"}},"outputs":[{"name":"stdout","text":"Total number of pest classes: 132\n","output_type":"stream"},{"name":"stderr","text":"Analyzing dataset:  92%|█████████▏| 122/132 [05:26<00:23,  2.31s/it]","output_type":"stream"},{"name":"stdout","text":"Corrupted image: /kaggle/input/pestopia/Datasets/Pest_Dataset/bollworm/bollworm, Error: [Errno 21] Is a directory: '/kaggle/input/pestopia/Datasets/Pest_Dataset/bollworm/bollworm'\n","output_type":"stream"},{"name":"stderr","text":"Analyzing dataset: 100%|██████████| 132/132 [05:46<00:00,  2.63s/it]","output_type":"stream"},{"name":"stdout","text":"Total images found: 55864\nMissing or corrupted files: 1\nCorrupted files: 1\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Step 3: Load pesticide CSV\npesticide_df = pd.read_csv(pesticide_csv)\nprint(\"\\nPesticide CSV Preview:\")\nprint(pesticide_df.head())\nprint(f\"Unique pests in CSV: {pesticide_df['Pest Name'].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:46:31.920647Z","iopub.execute_input":"2025-06-11T10:46:31.921069Z","iopub.status.idle":"2025-06-11T10:46:31.949891Z","shell.execute_reply.started":"2025-06-11T10:46:31.921038Z","shell.execute_reply":"2025-06-11T10:46:31.949223Z"}},"outputs":[{"name":"stdout","text":"\nPesticide CSV Preview:\n                  Pest Name                   Most Commonly Used Pesticides\n0             Adristyrannus                 Acephate, Malathion, Permethrin\n1  Aleurocanthus spiniferus         Imidacloprid, Acetamiprid, Chlorpyrifos\n2         alfalfa plant bug  Imidacloprid, Lambda-cyhalothrin, Chlorpyrifos\n3      alfalfa seed chalcid            Azadirachtin, Imidacloprid, Spinosad\n4            alfalfa weevil              Chlorpyrifos, Cyfluthrin, Carbaryl\nUnique pests in CSV: 132\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"base_dir = \"/kaggle/input/pestopia/Datasets/Pest_Dataset\"\nsubset_dir = \"/kaggle/working/pestopia_subset\"\nflat_subset_dir = \"/kaggle/working/pestopia_subset_flat\"\nos.makedirs(subset_dir, exist_ok=True)\nos.makedirs(flat_subset_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:46:31.950615Z","iopub.execute_input":"2025-06-11T10:46:31.950930Z","iopub.status.idle":"2025-06-11T10:46:31.955239Z","shell.execute_reply.started":"2025-06-11T10:46:31.950905Z","shell.execute_reply":"2025-06-11T10:46:31.954534Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def collect_image_paths(base_dir):\n    pest_classes = os.listdir(base_dir)\n    pest_classes = [p for p in pest_classes if os.path.isdir(os.path.join(base_dir, p))]\n    image_paths = []\n    labels = []\n\n    for pest in tqdm(pest_classes, desc=\"Collecting image paths\"):\n        pest_dir = os.path.join(base_dir, pest)\n        for img_name in os.listdir(pest_dir):\n            img_path = os.path.join(pest_dir, img_name)\n            image_paths.append(img_path)\n            labels.append(pest)\n\n    return image_paths, labels, pest_classes\n\nimage_paths, labels, pest_classes = collect_image_paths(base_dir)\nprint(f\"Total images: {len(image_paths)}\")\nprint(f\"Total pest classes: {len(pest_classes)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:46:31.957335Z","iopub.execute_input":"2025-06-11T10:46:31.957532Z","iopub.status.idle":"2025-06-11T10:46:32.152340Z","shell.execute_reply.started":"2025-06-11T10:46:31.957517Z","shell.execute_reply":"2025-06-11T10:46:32.151544Z"}},"outputs":[{"name":"stderr","text":"Collecting image paths: 100%|██████████| 132/132 [00:00<00:00, 1094.58it/s]","output_type":"stream"},{"name":"stdout","text":"Total images: 55865\nTotal pest classes: 132\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"target_images = 10000  # Reduced subset for faster annotation\nproportion = target_images / len(image_paths)\nimages_per_class = {pest: 0 for pest in pest_classes}\n\n# Count images per class\nfor label in labels:\n    images_per_class[label] += 1\n\n# Target images per class (minimum 1 image per class)\ntarget_per_class = {}\nfor pest in pest_classes:\n    current_count = images_per_class[pest]\n    target_count = max(1, int(current_count * proportion))\n    target_per_class[pest] = target_count\n\n# Adjust to ensure total is exactly 1,000\ntotal_target = sum(target_per_class.values())\nif total_target != target_images:\n    scaling_factor = target_images / total_target\n    for pest in target_per_class:\n        target_per_class[pest] = max(1, int(target_per_class[pest] * scaling_factor))\n\ntotal_target = sum(target_per_class.values())\nif total_target > target_images:\n    excess = total_target - target_images\n    sorted_classes = sorted(target_per_class.items(), key=lambda x: x[1], reverse=True)\n    for pest, count in sorted_classes:\n        if excess <= 0:\n            break\n        reduce_by = min(excess, count - 1)\n        target_per_class[pest] -= reduce_by\n        excess -= reduce_by\n\n# Step 4: Sample images for the subset\nsubset_paths = []\nsubset_labels = []\n\nfor pest in tqdm(pest_classes, desc=\"Creating subset\"):\n    pest_paths = [p for p, l in zip(image_paths, labels) if l == pest]\n    target_count = target_per_class[pest]\n    if len(pest_paths) <= target_count:\n        selected_paths = pest_paths\n    else:\n        selected_paths = pest_paths[:target_count]\n    subset_paths.extend(selected_paths)\n    subset_labels.extend([pest] * len(selected_paths))\n\nprint(f\"Subset created: {len(subset_paths)} images\")\n\n# Step 5: Copy images to subset directory with class subdirectories\nfor img_path, label in tqdm(zip(subset_paths, subset_labels), total=len(subset_paths), desc=\"Copying images to subset\"):\n    class_dir = os.path.join(subset_dir, label)\n    os.makedirs(class_dir, exist_ok=True)\n    img_name = os.path.basename(img_path)\n    dest_path = os.path.join(class_dir, img_name)\n    shutil.copy(img_path, dest_path)\n\nprint(f\"Subset copied to {subset_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:46:32.153010Z","iopub.execute_input":"2025-06-11T10:46:32.153205Z","iopub.status.idle":"2025-06-11T10:46:44.126643Z","shell.execute_reply.started":"2025-06-11T10:46:32.153189Z","shell.execute_reply":"2025-06-11T10:46:44.125915Z"}},"outputs":[{"name":"stderr","text":"Creating subset: 100%|██████████| 132/132 [00:00<00:00, 567.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Subset created: 9952 images\n","output_type":"stream"},{"name":"stderr","text":"Copying images to subset: 100%|██████████| 9952/9952 [00:11<00:00, 849.14it/s]","output_type":"stream"},{"name":"stdout","text":"Subset copied to /kaggle/working/pestopia_subset\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Step 6: Flatten the directory structure for Roboflow upload\nfor label in tqdm(subset_labels, desc=\"Flattening directory\"):\n    class_dir = os.path.join(subset_dir, label)\n    for img_name in os.listdir(class_dir):\n        src_path = os.path.join(class_dir, img_name)\n        # Rename the image to include the class name (e.g., grasshopper_image1.jpg)\n        base_name, ext = os.path.splitext(img_name)\n        new_img_name = f\"{label}_{base_name}{ext}\"\n        dest_path = os.path.join(flat_subset_dir, new_img_name)\n        shutil.copy(src_path, dest_path)\n\nflat_images = os.listdir(flat_subset_dir)\nprint(f\"Flattened subset created: {len(flat_images)} images in {flat_subset_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:46:44.127376Z","iopub.execute_input":"2025-06-11T10:46:44.127630Z","iopub.status.idle":"2025-06-11T10:52:44.689716Z","shell.execute_reply.started":"2025-06-11T10:46:44.127578Z","shell.execute_reply":"2025-06-11T10:52:44.688980Z"}},"outputs":[{"name":"stderr","text":"Flattening directory: 100%|██████████| 9952/9952 [06:00<00:00, 27.60it/s]  ","output_type":"stream"},{"name":"stdout","text":"Flattened subset created: 9952 images in /kaggle/working/pestopia_subset_flat\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Step 1: Define paths\nflat_subset_dir = \"/kaggle/working/pestopia_subset_flat\"\nzip_file_path = \"/kaggle/working/pestopia_subset_flat.zip\"\n\n# Step 2: Verify the contents of the flattened subset directory\nif not os.path.exists(flat_subset_dir):\n    raise FileNotFoundError(f\"Directory {flat_subset_dir} does not exist. Ensure you have run the previous steps to create the flattened subset.\")\n\nflat_images = [f for f in os.listdir(flat_subset_dir) if os.path.isfile(os.path.join(flat_subset_dir, f))]\nprint(f\"Found {len(flat_images)} images in {flat_subset_dir}\")\n\nif len(flat_images) == 0:\n    raise ValueError(f\"No images found in {flat_subset_dir}. Ensure the directory contains image files.\")\n\n# Step 3: Create a ZIP file of the flattened subset\nprint(f\"Creating ZIP file at {zip_file_path}...\")\nshutil.make_archive(\n    base_name=\"/kaggle/working/pestopia_subset_flat\",  # Base name for the ZIP file (without .zip extension)\n    format=\"zip\",  # Format of the archive\n    root_dir=flat_subset_dir  # Directory to zip\n)\n\n# Step 4: Verify the ZIP file was created\nif not os.path.exists(zip_file_path):\n    raise FileNotFoundError(f\"Failed to create ZIP file at {zip_file_path}.\")\n\nzip_size = os.path.getsize(zip_file_path) / (1024 * 1024)  # Size in MB\nprint(f\"ZIP file created: {zip_file_path} ({zip_size:.2f} MB)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:57:27.509207Z","iopub.execute_input":"2025-06-11T10:57:27.509540Z","iopub.status.idle":"2025-06-11T10:57:42.130658Z","shell.execute_reply.started":"2025-06-11T10:57:27.509518Z","shell.execute_reply":"2025-06-11T10:57:42.129904Z"}},"outputs":[{"name":"stdout","text":"Found 9952 images in /kaggle/working/pestopia_subset_flat\nCreating ZIP file at /kaggle/working/pestopia_subset_flat.zip...\nZIP file created: /kaggle/working/pestopia_subset_flat.zip (393.15 MB)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Step 7: Upload to Roboflow with verification and error handling\napi_key = \"LGaRRqVtNzMpwOIEe6oD\"\nworkspace = \"sus-ltlqs\"  # This might be incorrect; we'll verify\nproject_name = \"pestopia-annotation\"\n\ntry:\n    # Initialize Roboflow\n    rf = Roboflow(api_key=api_key)\n    \n    # Step 7.1: Verify the workspace\n    print(\"Verifying workspace...\")\n    workspaces = rf.workspaces()\n    workspace_names = [w[\"name\"] for w in workspaces]\n    print(f\"Available workspaces: {workspace_names}\")\n    \n    if workspace not in workspace_names:\n        raise ValueError(f\"Workspace '{workspace}' not found. Available workspaces: {workspace_names}. Please check your workspace name or API key permissions.\")\n    \n    # Step 7.2: Check if the project exists, create if it doesn't\n    print(f\"Checking for project '{project_name}' in workspace '{workspace}'...\")\n    workspace_obj = rf.workspace(workspace)\n    projects = workspace_obj.projects()\n    project_names = [p[\"name\"] for p in projects]\n    print(f\"Existing projects in workspace '{workspace}': {project_names}\")\n    \n    if project_name not in project_names:\n        print(f\"Project '{project_name}' does not exist. Creating it...\")\n        project = workspace_obj.create_project(\n            project_name=project_name,\n            project_type=\"object-detection\",  # For bounding box annotations\n            annotation=\"pest-classification\"\n        )\n        print(f\"Created project: {project_name}\")\n    else:\n        project = workspace_obj.project(project_name)\n        print(f\"Project '{project_name}' already exists. Using existing project.\")\n\n    # Step 7.3: Upload the flattened dataset\n    print(f\"Uploading {len(flat_images)} images to Roboflow project: {project_name}\")\n    project.upload(flat_subset_dir, num_workers=10)  # Upload with 10 concurrent workers\n    print(f\"Successfully uploaded {len(flat_images)} images to Roboflow project: {project_name}\")\n\nexcept Exception as e:\n    print(f\"Error during Roboflow upload: {e}\")\n    print(\"Troubleshooting steps:\")\n    print(\"1. Verify your API key is correct and has permissions.\")\n    print(\"2. Check if the workspace name is correct (run `rf.workspaces()` to list available workspaces).\")\n    print(\"3. Ensure the project exists or can be created.\")\n    print(\"4. Verify that {flat_subset_dir} contains only image files (no subdirectories).\")\n    print(\"5. Check your internet connection and Roboflow's status.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:52:44.690496Z","iopub.execute_input":"2025-06-11T10:52:44.690769Z","iopub.status.idle":"2025-06-11T10:52:44.962686Z","shell.execute_reply.started":"2025-06-11T10:52:44.690746Z","shell.execute_reply":"2025-06-11T10:52:44.961930Z"}},"outputs":[{"name":"stdout","text":"Verifying workspace...\nError during Roboflow upload: 'Roboflow' object has no attribute 'workspaces'\nTroubleshooting steps:\n1. Verify your API key is correct and has permissions.\n2. Check if the workspace name is correct (run `rf.workspaces()` to list available workspaces).\n3. Ensure the project exists or can be created.\n4. Verify that {flat_subset_dir} contains only image files (no subdirectories).\n5. Check your internet connection and Roboflow's status.\n","output_type":"stream"}],"execution_count":10}]}